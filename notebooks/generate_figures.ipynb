{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-31T04:03:09.809439Z",
     "iopub.status.busy": "2021-03-31T04:03:09.808962Z",
     "iopub.status.idle": "2021-03-31T04:03:22.480227Z",
     "shell.execute_reply": "2021-03-31T04:03:22.479714Z",
     "shell.execute_reply.started": "2021-03-31T04:03:09.809316Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import guild.ipy as guild\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import transforms\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from guild import tfevent, config\n",
    "from itertools import chain\n",
    "\n",
    "# config.set_guild_home(\"/home/miniconda3/envs/envname/.guild\")\n",
    "guild_runs = guild.runs()\n",
    "flags = guild_runs.flags()\n",
    "scalars = guild_runs.scalars()\n",
    "HOME = config.guild_home()\n",
    "orig_runs = guild_runs.compare()\n",
    "sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-31T04:03:22.481087Z",
     "iopub.status.busy": "2021-03-31T04:03:22.480960Z",
     "iopub.status.idle": "2021-03-31T04:03:22.485756Z",
     "shell.execute_reply": "2021-03-31T04:03:22.485354Z",
     "shell.execute_reply.started": "2021-03-31T04:03:22.481072Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-31T04:04:34.357339Z",
     "iopub.status.busy": "2021-03-31T04:04:34.356911Z",
     "iopub.status.idle": "2021-03-31T04:04:34.396602Z",
     "shell.execute_reply": "2021-03-31T04:04:34.396116Z",
     "shell.execute_reply.started": "2021-03-31T04:04:34.357294Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "# today_mask = runs[\"started\"].apply(lambda d: d.date()) >= date.today()\n",
    "ndays_ago = 40\n",
    "nhours_ago = 5\n",
    "# today_mask = runs[\"started\"].apply(lambda d: d.date()) >= date.today() - timedelta(days=ndays_ago, hours=nhours_ago)\n",
    "today_mask = orig_runs[\"started\"] >= datetime.now() - timedelta(days=ndays_ago, hours=nhours_ago)\n",
    "no_errors_mask = orig_runs[\"status\"] != \"error\"\n",
    "imputer_task_mask = orig_runs[\"operation\"] == \"imputer\"\n",
    "\n",
    "# I want to ignore the previous APs and just use the current one because my fixes are in the current one\n",
    "# tmp_ignore = (orig_runs[\"started\"] < datetime.now() - timedelta(days=1)) & (orig_runs[\"label\"] == \"ap ckd\")\n",
    "\n",
    "mask = today_mask & no_errors_mask & imputer_task_mask # & ~tmp_ignore\n",
    "runs = orig_runs[mask]\n",
    "\n",
    "\n",
    "flags_mask = flags[\"run\"].str[:8].isin(runs[\"run\"].astype(str))\n",
    "flags = flags[flags_mask]\n",
    "scalars_mask = scalars[\"run\"].str[:8].isin(runs[\"run\"].astype(str))\n",
    "scalars = scalars[scalars_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-31T04:52:25.837295Z",
     "iopub.status.busy": "2021-03-31T04:52:25.836807Z",
     "iopub.status.idle": "2021-03-31T04:52:25.847723Z",
     "shell.execute_reply": "2021-03-31T04:52:25.846558Z",
     "shell.execute_reply.started": "2021-03-31T04:52:25.837244Z"
    }
   },
   "outputs": [],
   "source": [
    "imputer_mapping = [\"simple\", \"knn\", \"mice\", \"mida\", \"dae_mvec\", \"vae_ifac\", \"ap_new\"]\n",
    "imputer_order = [\"Simple\", \"KNN\", \"MICE\", \"MIDA\", \"DAE\", \"VAE\", \"APnew\"]\n",
    "mechanism_order = [\"MCAR\", \"MAR\", \"MNAR\"]\n",
    "# percent_order = [\"0.33\", \"0.66\"]\n",
    "percent_order = [33.0, 66.0]\n",
    "predictor_mapping = [\"logistic_regression\", \"random_forest\"]\n",
    "predictor_order = [\"Logistic Regression\", \"Random Forest\"]\n",
    "# predict_metric_order = [\"TN\", \"FP\", \"TP\", \"FN\", \"Brier-score\", \"F1-score\", \"Precision-score\", \"Recall-score\", \"PR-AUC\", \"ROC-AUC\"] # If colwrap=2\n",
    "# predict_metric_mapping = [\"TN\", \"FP\", \"TP\", \"FN\", \"Brier-score\", \"F1-score\", \"Precision-score\", \"Recall-score\", \"PR-AUC\", \"ROC-AUC\"] # If colwrap=2\n",
    "# predict_metric_order = [\"True Negative\", \"False Positive\", \"True Positive\", \"False Negative\", \"Brier-score\", \"F1-score\", \"Precision-score\", \"Recall-score\", \"PR-AUC\", \"ROC-AUC\"] # If colwrap=2\n",
    "# ignores F1 score\n",
    "predict_metric_mapping = [\"TN\", \"FP\", \"TP\", \"FN\", \"Brier-score\", \"Precision-score\", \"Recall-score\", \"PR-AUC\", \"ROC-AUC\"] \n",
    "predict_metric_order = [\"True Negative\", \"False Positive\", \"True Positive\", \"False Negative\", \"Brier-score\", \"Precision-score\", \"Recall-score\", \"PR-AUC\", \"ROC-AUC\"] \n",
    "name_mapping = {\n",
    "        \"Method\": dict(zip(imputer_mapping, imputer_order)),\n",
    "        \"Predictive Model\": dict(zip(predictor_mapping, predictor_order)),\n",
    "        \"Imputation Metric\": {\"RMSE-missingonly\": \"RMSE\", \"MAAPE-missingonly\": \"MAAPE\", \"AccuracyPerBin-missingonly\": \"Accuracy Over Bins\"},\n",
    "        \"Metric\": dict(zip(predict_metric_mapping, predict_metric_order))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-31T04:52:26.003233Z",
     "iopub.status.busy": "2021-03-31T04:52:26.002793Z",
     "iopub.status.idle": "2021-03-31T04:52:26.039030Z",
     "shell.execute_reply": "2021-03-31T04:52:26.038141Z",
     "shell.execute_reply.started": "2021-03-31T04:52:26.003187Z"
    }
   },
   "outputs": [],
   "source": [
    "runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-31T04:52:26.327958Z",
     "iopub.status.busy": "2021-03-31T04:52:26.327527Z",
     "iopub.status.idle": "2021-03-31T04:52:26.413013Z",
     "shell.execute_reply": "2021-03-31T04:52:26.412533Z",
     "shell.execute_reply.started": "2021-03-31T04:52:26.327914Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "test_mask = scalars[\"tag\"].str.startswith(\"impute/test-\")\n",
    "fully_observed_mask = scalars[\"prefix\"].str.startswith(\"F.O.\")\n",
    "values = scalars[test_mask & fully_observed_mask]\n",
    "values[[\"percent\", \"mech\", \"method\"]] = values[\"prefix\"].str.split(\"/\", expand=True).drop(0, axis=1)\n",
    "# get the metric name (everything after impute/test-)\n",
    "values[\"metric\"] = values[\"tag\"].str[len(\"impute/test-\"):]\n",
    "table = pd.DataFrame()\n",
    "table[[\"Imputation Metric\", \"Percent\", \"Mechanism\", \"Method\", \"first_val\"]] = values[[\"metric\", \"percent\", \"mech\", \"method\", \"first_val\"]]\n",
    "\n",
    "# Filter for missing only\n",
    "table = table[table[\"Imputation Metric\"].str.endswith(\"missingonly\")]\n",
    "\n",
    "# Rename for figure\n",
    "for col_name, col_mapping in name_mapping.items():\n",
    "    if col_name in table:\n",
    "        table[col_name] = table[col_name].map(col_mapping)\n",
    "        \n",
    "\n",
    "table[\"Percent\"] = table[\"Percent\"].astype(float)*100\n",
    "\n",
    "\n",
    "def impute_table_to_latex(table: pd.DataFrame) -> str:\n",
    "    table = table[table[\"Imputation Metric\"] != \"Accuracy Over Bins\"]\n",
    "    table = table.pivot_table(index=[\"Imputation Metric\", \"Mechanism\", \"Percent\"], columns=\"Method\", values=\"first_val\") \n",
    "    table = table[imputer_order]\n",
    "    display(table)\n",
    "    latex = table.to_latex(float_format=\"%.3f\")\n",
    "#     print(latex)\n",
    "    return latex\n",
    "impute_table_to_latex(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-31T04:52:26.733422Z",
     "iopub.status.busy": "2021-03-31T04:52:26.732938Z",
     "iopub.status.idle": "2021-03-31T04:52:27.760189Z",
     "shell.execute_reply": "2021-03-31T04:52:27.759742Z",
     "shell.execute_reply.started": "2021-03-31T04:52:26.733371Z"
    }
   },
   "outputs": [],
   "source": [
    "# with sns.plotting_context(font_scale=1.5):\n",
    "table_without_binaccuracy = table[table[\"Imputation Metric\"] != \"Accuracy Over Bins\"]\n",
    "g = sns.catplot(x=\"Method\", y=\"first_val\", hue=\"Percent\", col=\"Mechanism\", row=\"Imputation Metric\", data=table_without_binaccuracy,\n",
    "                ci=None, sharey=\"row\", legend=False,\n",
    "                hue_order=percent_order, order=imputer_order, col_order=mechanism_order,\n",
    "                markers=[\"o\", \"x\"], join=False, #linestyles=[\"-\", \"--\"], \n",
    "                margin_titles=True, kind=\"point\")\n",
    "g.add_legend(loc=\"upper right\", bbox_to_anchor=(0.5, 1.10), ncol=2, title=\"Percent Missing\", frameon=True)\n",
    "g.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\").set_xticklabels(rotation=45).set_axis_labels(\"Imputation Method\", \"\").tight_layout()\n",
    "plt.suptitle(\"Imputation Metrics\", x= 0.39, y=1.135, weight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap version\n",
    "# from matplotlib import pyplot\n",
    "# tmp = table_without_binaccuracy.pivot_table(index=[\"Method\"], columns=[\"Percent\", \"Imputation Metric\", \"Mechanism\"], values=\"first_val\")\n",
    "# fig, ax = pyplot.subplots(figsize=(20,5))\n",
    "# g = sns.heatmap(tmp, yticklabels=imputer_order, annot=True, ax=ax)\n",
    "# # tmp.unstack()\n",
    "\n",
    "def draw_heatmap(*args, **kwargs):\n",
    "    data = kwargs.pop('data')\n",
    "    # d = data.pivot_table(index=[\"Method\"], columns=[\"Percent\"], values=\"first_val\")\n",
    "    d = data.pivot_table(index=[\"Percent\"], columns=[\"Method\"], values=\"first_val\")\n",
    "    sns.heatmap(d, annot=True, **kwargs)\n",
    "\n",
    "g = sns.FacetGrid(table_without_binaccuracy, col=\"Mechanism\", row=\"Imputation Metric\", col_order=mechanism_order,\n",
    "                    margin_titles=True, height=3, aspect=3)\n",
    "# g.map(sns.heatmap, \"first_val\", annot=True)\n",
    "g.map_dataframe(draw_heatmap)\n",
    "g.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\").set_xticklabels(rotation=45).set_axis_labels(\"Percent Missing\", \"\").tight_layout()\n",
    "plt.suptitle(\"Imputation Metrics\", x= 0.5, y=1.05, weight=\"bold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-31T05:37:44.156988Z",
     "iopub.status.busy": "2021-03-31T05:37:44.156524Z",
     "iopub.status.idle": "2021-03-31T05:37:44.298730Z",
     "shell.execute_reply": "2021-03-31T05:37:44.298286Z",
     "shell.execute_reply.started": "2021-03-31T05:37:44.156941Z"
    }
   },
   "outputs": [],
   "source": [
    "# table[table[\"Imputation Metric\"] == \"Accuracy Over Bins\"]\n",
    "g = sns.barplot(x=\"Mechanism\", y=\"first_val\", hue=\"Percent\", data=table[table[\"Imputation Metric\"] == \"Accuracy Over Bins\"],\n",
    "                order=mechanism_order)\n",
    "# dir(g)\n",
    "# set hatches for alternate to visually distinguish aside from color\n",
    "hatches = [None, \"///\"]\n",
    "j = -1\n",
    "# will iterate over each colour at a time from left to right, so it will iterate over the left blue bar, then middle, then right, then the left orange bar, etc.\n",
    "for i, bar in enumerate(g.patches):\n",
    "    # every number columns change the hatch pattern\n",
    "    if  i % len(mechanism_order) == 0:\n",
    "        j += 1\n",
    "    bar.set_hatch(hatches[j])\n",
    "\n",
    "g.set_ylabel(\"\")\n",
    "plt.suptitle(\"Accuracy Over Bins\", y=1.25)\n",
    "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.40), ncol=2, title=\"Percent Missing\")\n",
    "\n",
    "def binacc_table_to_latex(table: pd.DataFrame) -> str:\n",
    "    table = table[table[\"Imputation Metric\"] == \"Accuracy Over Bins\"]\n",
    "    table = table.pivot_table(index=[\"Mechanism\", \"Percent\"], values=\"first_val\") \n",
    "    display(table)\n",
    "    latex = table.to_latex(float_format=\"%.3f\")\n",
    "    print(latex)\n",
    "binacc_table_to_latex(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Task Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-31T04:04:42.429642Z",
     "iopub.status.busy": "2021-03-31T04:04:42.429150Z",
     "iopub.status.idle": "2021-03-31T04:04:42.549783Z",
     "shell.execute_reply": "2021-03-31T04:04:42.549224Z",
     "shell.execute_reply.started": "2021-03-31T04:04:42.429588Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_mask = scalars[\"tag\"].str.startswith(\"predict/\")\n",
    "full_mask = scalars[\"prefix\"].str.startswith(\"full\")\n",
    "res = scalars[predict_mask & full_mask]\n",
    "# if prefix == \"F.O.\":  # filter for fully observed\n",
    "#     res = res[res[\"prefix\"].str.startswith(\"F.O.\")]\n",
    "#     res[[\"data\", \"percent\", \"mech\", \"method\", \"model\"]] = res[\"prefix\"].str.split(\"/\", expand=True)\n",
    "\n",
    "res[[\"data\", \"method\", \"model\"]] = res[\"prefix\"].str.split(\"/\", expand=True)\n",
    "\n",
    "res[\"metric\"] = res[\"tag\"].apply(lambda logname: logname.split(\"/\")[-1])\n",
    "\n",
    "aggregate_mask = scalars[\"tag\"].str.startswith(\"predict-aggregate/\") \n",
    "full_mask = scalars[\"prefix\"].str.startswith(\"full\")\n",
    "lower_mask = scalars[\"tag\"].str.endswith(\"-lower\") \n",
    "upper_mask = scalars[\"tag\"].str.endswith(\"-upper\") \n",
    "err_lower = scalars[aggregate_mask & lower_mask & full_mask][\"first_val\"]\n",
    "err_upper = scalars[aggregate_mask & upper_mask & full_mask][\"first_val\"]\n",
    "err_lower.index = res.index\n",
    "err_upper.index = res.index\n",
    "res[\"err_lower\"] = err_lower\n",
    "res[\"err_upper\"] = err_upper\n",
    "# err_upper[\"first_val\"].subtract(err_lower[\"first_val\"], fill_value=0)\n",
    "\n",
    "# validation: checking that the order is exactly the same so i don't have to worry\n",
    "# pd.concat([res[\"prefix\"].reset_index(drop=True), err_lower[\"prefix\"].reset_index(drop=True), err_upper[\"prefix\"].reset_index(drop=True)],axis=1)\n",
    "\n",
    "res = res[[\"metric\", \"method\", \"model\", \"avg_val\", \"err_lower\", \"err_upper\"]]\n",
    "res.rename(columns={\"metric\": \"Metric\", \"method\": \"Method\", \"model\": \"Predictive Model\"}, inplace=True)\n",
    "# Rename for figure\n",
    "for col_name, col_mapping in name_mapping.items():\n",
    "    if col_name in res:\n",
    "        res[col_name] = res[col_name].map(col_mapping)\n",
    "\n",
    "def pred_table_to_latex(res: pd.DataFrame) -> str:\n",
    "    res = res.pivot_table(index=[\"Metric\", \"Predictive Model\"], columns=\"Method\", values=\"avg_val\") \n",
    "    res = res[imputer_order]\n",
    "    display(res)\n",
    "    latex = res.to_latex(float_format=\"%.3f\")\n",
    "#     print(latex)\n",
    "    return latex\n",
    "pred_table_to_latex(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-31T04:48:19.567732Z",
     "iopub.status.busy": "2021-03-31T04:48:19.567152Z",
     "iopub.status.idle": "2021-03-31T04:48:22.253675Z",
     "shell.execute_reply": "2021-03-31T04:48:22.253235Z",
     "shell.execute_reply.started": "2021-03-31T04:48:19.567677Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "g = sns.catplot(x=\"Method\", y=\"avg_val\", hue=\"Predictive Model\", col=\"Metric\", data=res,\n",
    "                order=imputer_order, col_order=predict_metric_order, hue_order=predictor_order,\n",
    "                markers=[\"o\", \"x\"], join=False, # linestyles=[\"-\", \"--\"], \n",
    "                sharey=False, col_wrap=3, aspect=1.3,\n",
    "                dodge=0.2, kind=\"point\",\n",
    "                legend=False)\n",
    "# g.map(plt.errorbar, x=\"method\", y=\"avg_val\", hue=\"model\", col=\"metric\", yerr=[\"err_lower\", \"err_upper\"])\n",
    "\n",
    "def plot_errbar(x: str, y: str, hue: str, data: pd.DataFrame, order, **kwargs):\n",
    "    \"\"\"Plots error bar into each facet in the facetgrid from seaborn with dodge + color per hue.\"\"\"\n",
    "    # get everything pivoted to have a column per hue, and then sort index\n",
    "    err_lower = data.pivot(index=x, columns=hue, values=\"err_lower\").T[order].T\n",
    "    err_upper = data.pivot(index=x, columns=hue, values=\"err_upper\").T[order].T\n",
    "    median = data.pivot(index=x, columns=hue, values=y).T[order].T\n",
    "    err_lower = median - err_lower\n",
    "    err_upper = err_upper - median\n",
    "\n",
    "    ax = plt.gca()\n",
    "    colors = sns.color_palette()\n",
    "    for i, hue in enumerate(err_lower):\n",
    "        dodge = 6*i if i != 0 else -5\n",
    "        trans = ax.transData + transforms.ScaledTranslation(dodge/72., 0, ax.figure.dpi_scale_trans)\n",
    "        ax.errorbar(x=median[hue].index, y=median[hue], yerr=[err_lower[hue].values, err_upper[hue].values],\n",
    "                    ecolor=colors[i], fmt='none', transform=trans, **kwargs)\n",
    "g.map_dataframe(plot_errbar, x=\"Method\", y=\"avg_val\", hue=\"Predictive Model\", order=imputer_order)\n",
    "\n",
    "\n",
    "# place boxes upper right hand corner at x,y for bbox\n",
    "g.add_legend(loc=\"upper right\", bbox_to_anchor=(0.5, 1.07), ncol=2, title=\"Predictive Model\", frameon=True)\n",
    "g.set_titles(col_template=\"{col_name}\").set_xticklabels(rotation=45).set_axis_labels(\"Imputation Method\", \"\").tight_layout()\n",
    "plt.suptitle(\"Prediction Metrics\", x=0.35, y=1.09, weight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HeatMap Version\n",
    "ignore_metrics = [\"True Negative\", \"True Positive\", \"False Positive\", \"False Negative\"]\n",
    "a = res[res[\"Predictive Model\"] == \"Logistic Regression\"].pivot_table(index=[\"Metric\", \"Method\"], values=\"avg_val\")\n",
    "# ignore the large scale ones\n",
    "a = a[~a.index.get_level_values(\"Metric\").isin(ignore_metrics)]\n",
    "a = a.unstack()\n",
    "\n",
    "# g = sns.heatmap(a.unstack()*100, annot=a)\n",
    "# a.apply(lambda : a.quantile(row), axis=1, result_type=\"expand\")\n",
    "a.quantile(np.linspace(.1, 1, 9, 0))\n",
    "# LAID TO REST: the different metrics are on different scales :( I would only be able to heatmap some of them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-31T04:04:45.061938Z",
     "iopub.status.busy": "2021-03-31T04:04:45.061810Z",
     "iopub.status.idle": "2021-03-31T04:04:45.334465Z",
     "shell.execute_reply": "2021-03-31T04:04:45.334025Z",
     "shell.execute_reply.started": "2021-03-31T04:04:45.061923Z"
    }
   },
   "outputs": [],
   "source": [
    "# help(runs.iloc[0][\"run\"].value)\n",
    "# keep = runs[\"operation\"] == \"imputer\"\n",
    "# timings = runs[keep].compare()\n",
    "# timings[[\"time\", \"method\", \"percent-missing\", \"missingness-mechanism\"]].pivot_table(index=[\"percent-missing\", \"missingness-mechanism\"], columns=\"method\", values=\"time\")\n",
    "# convert string time to integer second\n",
    "grouped_timings = runs[[\"method\", \"fully-observed\", \"predictors\"]]\n",
    "grouped_timings[\"time\"] = runs[\"time\"].dt.seconds\n",
    "ax = sns.pointplot(data=grouped_timings, x=\"method\", y=\"time\", hue=\"fully-observed\")\n",
    "ax.set_xlabel(\"Imputation Method\")\n",
    "ax.set_ylabel(\"Time (seconds)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('ap': conda)",
   "name": "python388jvsc74a57bd04326de75351ef303f1e4a122f200f160439800d16731350d51fc2a0864c0e618"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}